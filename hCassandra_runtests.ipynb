{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hCassandra runTests\n",
    "\n",
    "## Description\n",
    "\n",
    "---\n",
    "\n",
    "### Objective\n",
    "\n",
    "   This test aims to **automate**:\n",
    "   \n",
    "   (1) The execution of the Hydra Cassandra Stress Test (hCassandra) for increasing client load.\n",
    "   \n",
    "   (2) The generation of performance results presented in the form of tables and graphs for relevant metrics. \n",
    "   \n",
    "   To this end, performance of the Cassandra Cluster is measured as the number of clients writing and reading into the DataBase is increased. The number of clients can be defined by the user. \n",
    "   \n",
    " \n",
    "### Customize the Test\n",
    "\n",
    "   Modify **total_num_clients** to change the sets of clients for which you wish to execute the test.\n",
    "   \n",
    "   Current tests have been run for a maximum of **10000** clients and a duration of 5 minutes against a 3-node Cluster (for further details on Software & Hardware specs please refer to the *Software & Hardware Specs* section).\n",
    "   \n",
    "### Useful HINTS for running the test\n",
    "\n",
    "- If test has been previously executed and output is still shown, you can restart (delete former results) by selecting in the top menu Cell -> All Output -> Clear\n",
    "- To run test, step on top of the code cells and press the 'run cell' button on the top menu. For automatic Run select from the top menu Cell -> Run All\n",
    "- If you wish to store your results. After RUN is finished, generate your own report by selecting FILE -> Download as -> Markdown (.md) (or any other preferred format)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software & Hardware Specs\n",
    "\n",
    "---\n",
    "\n",
    "The tests were executed on Google Cloud Servers, with the following specs:\n",
    "\n",
    "#### Cassandra Cluster\n",
    "\n",
    "- 3 Node Cluster, each with the following specs:\n",
    "   - 16 vCPUs\n",
    "   - RAM: 60 GB\n",
    "   - Disk: 60 GB\n",
    "   - OS: Debian 3.16.7-ckt25-2\n",
    "  \n",
    "- Cassandra + Cassandra-Tools Version: 3.0.6\n",
    "\n",
    "#### Hydra Cluster\n",
    "\n",
    "- **MASTER**: 1 Server\n",
    "   - 4 vCPUs\n",
    "   - RAM: 15 GB\n",
    "   - OS: Ubuntu 14.04\n",
    "\n",
    "- **SLAVES**: 9 Servers (hosts to the cassandra-stress tool)\n",
    "   - 16 vCPUs \n",
    "   - RAM: 60 GB\n",
    "   - Disk: 60 GB\n",
    "   - OS: Debian 3.16.7-ckt25-2\n",
    "   \n",
    "### Important \n",
    "\n",
    "- For the performance tests maximum file open limit (ulimit) had to be increased for the Master Node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## hCassandra Test 1: Fixed Number of Stress Clients (Debug Mode) \n",
    "\n",
    "---\n",
    "\n",
    "The following test runs a SINGLE execution of the Cassandra Test for a fixed number of clients (total_client_count) and operations (total_ops_count). Runs in debug mode: showing logger info during execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python ./src/hCassandra_test.py --cluster_ips='10.10.0.155,10.10.2.218,10.10.3.116' --total_client_count=8000 --total_ops_count=2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## hCassandra Test 2: Increasing the Number of stress clients (multiple runs)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**IMPORTANT**:\n",
    "\n",
    "   If you want to change the number of clients and/or number of operations for your test, please set values to desired in the following section:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define num Client(s) / Operation(s)\n",
    "total_num_clients = [10, 100, 200, 400, 800, 1600, 3200, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "total_ops_count = [1000000]\n",
    "duration_array = [5, 10, 10, 10, 10, 10, 30, 30, 60, 60, 60, 80, 80]\n",
    "# Set IPs of Nodes in Cassandra Cluster\n",
    "cassandra_cluster_ips = '10.10.0.71,10.10.0.45,10.10.0.61'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**UTIL FUNCTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "\n",
    "def get_result(test_stdout):\n",
    "    \"\"\"This Function gets (filters) the Cassandra Test Results from stdout\"\"\"\n",
    "    index_start = test_stdout.find('Cassandra Stress Results: \\n')\n",
    "    index_end = test_stdout.find('Calling Server shutdown')\n",
    "    if index_start != -1:\n",
    "        results = test_stdout[(index_start + len('Cassandra Stress Results: \\n')):index_end]\n",
    "        res_dict = ast.literal_eval(results)\n",
    "        return res_dict\n",
    "    else:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block of code is the actual **EXECUTION OF THE CASSANDRA SCALE TESTS**. This may take a couple of minutes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING CASSANDRA STRESS TESTS \n",
      "\n",
      "Test (1/13) in progress.. Please wait until test is completed..\n",
      "Test SUCCESFULLY completed... \n",
      "\n",
      "Test (2/13) in progress.. Please wait until test is completed..\n",
      "Test SUCCESFULLY completed... \n",
      "\n",
      "Test (3/13) in progress.. Please wait until test is completed..\n",
      "Test SUCCESFULLY completed... \n",
      "\n",
      "Test (4/13) in progress.. Please wait until test is completed..\n",
      "Test SUCCESFULLY completed... \n",
      "\n",
      "Test (5/13) in progress.. Please wait until test is completed..\n",
      "Test SUCCESFULLY completed... \n",
      "\n",
      "Test (6/13) in progress.. Please wait until test is completed..\n",
      "Test SUCCESFULLY completed... \n",
      "\n",
      "Test (7/13) in progress.. Please wait until test is completed..\n",
      "Test SUCCESFULLY completed... \n",
      "\n",
      "Test (8/13) in progress.. Please wait until test is completed..\n",
      "Test SUCCESFULLY completed... \n",
      "\n",
      "Test (9/13) in progress.. Please wait until test is completed..\n",
      "Test SUCCESFULLY completed... \n",
      "\n",
      "Test (10/13) in progress.. Please wait until test is completed..\n",
      "Test SUCCESFULLY completed... \n",
      "\n",
      "Test (11/13) in progress.. Please wait until test is completed..\n",
      "Test SUCCESFULLY completed... \n",
      "\n",
      "Test (12/13) in progress.. Please wait until test is completed..\n",
      "Test SUCCESFULLY completed... \n",
      "\n",
      "Test (13/13) in progress.. Please wait until test is completed..\n",
      "Test SUCCESFULLY completed... \n",
      "\n",
      "END OF TESTS:\n",
      "ALL TESTS HAVE BEEN COMPLETED. PLEASE PROCEED TO GENERATE GRAPHS & TABLES WITH PERFORMANCE RESULTS.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import json\n",
    "import signal\n",
    "\n",
    "hCassandra_results = dict()\n",
    "\n",
    "print 'STARTING CASSANDRA STRESS TESTS \\n'\n",
    "# Execute hCassandra_test for given client_count\n",
    "for idx1, clients in enumerate(total_num_clients):\n",
    "    for idx2, ops in enumerate(total_ops_count):\n",
    "        print ('Test (%s/%s) in progress.. Please wait until test is completed..' % ((len(total_ops_count) * idx1) + idx2 + 1,len(total_num_clients) * len(total_ops_count)))\n",
    "        # Execute hCassandra_test.py (python script for hCassandra Scale Test)\n",
    "        hcass_cmd = \"python ./src/hCassandra_test.py --cluster_ips=%s --total_client_count=%s --total_ops_count=%s --test_duration=%s\" % (cassandra_cluster_ips, clients, ops, duration_array[idx1])\n",
    "        stress_test = subprocess.Popen(hcass_cmd, stdout=subprocess.PIPE,\n",
    "                                          stderr=subprocess.PIPE, shell=True, preexec_fn=os.setsid)\n",
    "        stdout, stderr = stress_test.communicate()\n",
    "        results_dict = get_result(stdout)\n",
    "        if len(results_dict) <= 1:\n",
    "            print ('There was an ERROR while attempting to parse stdout...')\n",
    "            print 'STDOUT: %s' % stdout\n",
    "            print 'STDERR: %s' % stderr\n",
    "        if not str(clients) in hCassandra_results:\n",
    "            hCassandra_results[str(clients)] = dict()\n",
    "        hCassandra_results[str(clients)][str(ops)] = results_dict\n",
    "        print 'Test SUCCESFULLY completed... \\n'\n",
    "\n",
    "print 'END OF TESTS:'\n",
    "print 'ALL TESTS HAVE BEEN COMPLETED. PLEASE PROCEED TO GENERATE GRAPHS & TABLES WITH PERFORMANCE RESULTS.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "  **NOTE:**\n",
    "  \n",
    "  ---\n",
    "   \n",
    "   Wait until RESULTS (**hCassandra_results**) are generated for all cases, and then execute the following blocks to generate:\n",
    "   (1) Tables with results (markdown compatible) and \n",
    "   (2) Graphs.\n",
    "   \n",
    "   The **END OF TEST** is indicated by a message. Please wait...\n",
    "   \n",
    "   ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESULT PROCESSING & TABLE/ GRAPH GENERATION\n",
    "\n",
    "---\n",
    "\n",
    "In this section, we process the results for generating tables with performance values and graphs that reflect number of operations per second and median latency for increased number of clients. \n",
    "\n",
    "**NOTE**\n",
    "If you are interested in representing any other performance metric, follow the pattern followed for any of the two graps already provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('results_hcassandra.txt', 'w') as outfile:\n",
    "    json.dump(hCassandra_results, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ListTable(list):\n",
    "    \"\"\" Overridden list class which takes a 2-dimensional list of \n",
    "        the form [[1,2,3],[4,5,6]], and renders an HTML Table in \n",
    "        IPython Notebook. \"\"\"\n",
    "    \n",
    "    def _repr_html_(self):\n",
    "        html = [\"<table>\"]\n",
    "        for row in self:\n",
    "            html.append(\"<tr>\")\n",
    "            \n",
    "            for col in row:\n",
    "                html.append(\"<td>{0}</td>\".format(col))\n",
    "            \n",
    "            html.append(\"</tr>\")\n",
    "        html.append(\"</table>\")\n",
    "        return ''.join(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "results_per_ops = dict()\n",
    "\n",
    "# Table Format: Metrics\n",
    "header = [\n",
    "            '# Clients',\n",
    "            'total_ops',\n",
    "            'op/s',\n",
    "            'med',\n",
    "            '.95',\n",
    "            '.99',\n",
    "            'max',\n",
    "            'op_time'\n",
    "        ]\n",
    "\n",
    "data_matrix_write = ListTable()\n",
    "data_matrix_read = ListTable()\n",
    "\n",
    "data_matrix_write.append(header)\n",
    "data_matrix_read.append(header)\n",
    "\n",
    "results_per_ops[str(total_ops_count[0])] = dict()\n",
    "for idx1, clients in enumerate(total_num_clients):\n",
    "    if str(clients) in hCassandra_results:\n",
    "        res_dict = ast.literal_eval(hCassandra_results[str(clients)][str(ops)])\n",
    "        results_per_ops[str(total_ops_count[0])][str(clients)] = res_dict\n",
    "        data_matrix_write.append([clients, sum((ops for ops in res_dict['write']['total ops'])), sum((ops for ops in res_dict['write']['op/s'])), numpy.median(res_dict['write']['med']), numpy.percentile(res_dict['write']['.95'], 95), numpy.percentile(res_dict['write']['.99'], 99), max(res_dict['write']['max']), res_dict['write']['op_time'][0]])\n",
    "        data_matrix_read.append([clients, sum((ops for ops in res_dict['read']['total ops'])), sum((ops for ops in res_dict['read']['op/s'])), numpy.median(res_dict['read']['med']), numpy.percentile(res_dict['read']['.95'], 95), numpy.percentile(res_dict['read']['.99'], 99), max(res_dict['read']['max']), duration_array[idx1]])        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Generation: Table Format\n",
    "\n",
    "Next, results are displayed in a Table, following the markdown format..  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next table represents the results for the **WRITE** Operations:\n",
    "\n",
    "---\n",
    "\n",
    "*Table 1. \"Cassandra Performance over WRITE Operation.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "text_file = open(\"write_stats_\" + str(datetime.now().strftime(\"%m%d%Y_%H%M%S\")) + \".txt\", \"w\")\n",
    "text_file.write(\"%s\" % data_matrix_write)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td># Clients</td><td>total_ops</td><td>op/s</td><td>med</td><td>.95</td><td>.99</td><td>max</td><td>op_time</td></tr><tr><td>10</td><td>5610699</td><td>18702</td><td>0.4</td><td>0.8</td><td>1.3</td><td>203.7</td><td>00:05:00</td></tr><tr><td>100</td><td>88201737</td><td>147001</td><td>0.5</td><td>1.0</td><td>1.3</td><td>165.8</td><td>00:10:00</td></tr><tr><td>200</td><td>132617034</td><td>221027</td><td>0.7</td><td>1.455</td><td>2.819</td><td>202.8</td><td>00:10:00</td></tr><tr><td>400</td><td>172053376</td><td>286750</td><td>0.9</td><td>2.8</td><td>5.281</td><td>398.3</td><td>00:10:00</td></tr><tr><td>800</td><td>192706739</td><td>321178</td><td>1.3</td><td>5.305</td><td>9.9</td><td>10228.2</td><td>00:10:00</td></tr><tr><td>1600</td><td>198542059</td><td>330896</td><td>2.0</td><td>11.1</td><td>23.205</td><td>7952.4</td><td>00:10:00</td></tr><tr><td>3200</td><td>573617864</td><td>318781</td><td>3.5</td><td>19.7</td><td>45.005</td><td>12904.2</td><td>00:29:59</td></tr><tr><td>5000</td><td>580920345</td><td>322734</td><td>5.8</td><td>31.7</td><td>64.302</td><td>13338.4</td><td>00:30:00</td></tr><tr><td>6000</td><td>1137540200</td><td>316007</td><td>6.8</td><td>33.2</td><td>70.101</td><td>15280.4</td><td>01:00:00</td></tr><tr><td>7000</td><td>1146288352</td><td>318415</td><td>7.9</td><td>39.28</td><td>75.156</td><td>14498.7</td><td>01:00:00</td></tr><tr><td>8000</td><td>1141405644</td><td>317034</td><td>9.2</td><td>45.6</td><td>88.91</td><td>26445.9</td><td>00:59:59</td></tr><tr><td>9000</td><td>1492160316</td><td>310850</td><td>10.1</td><td>51.8</td><td>98.869</td><td>28970.3</td><td>01:20:00</td></tr><tr><td>10000</td><td>1518306852</td><td>316316</td><td>11.5</td><td>55.15</td><td>101.715</td><td>29907.5</td><td>01:20:00</td></tr></table>"
      ],
      "text/plain": [
       "[['# Clients', 'total_ops', 'op/s', 'med', '.95', '.99', 'max', 'op_time'],\n",
       " [10,\n",
       "  5610699,\n",
       "  18702,\n",
       "  0.40000000000000002,\n",
       "  0.80000000000000004,\n",
       "  1.3,\n",
       "  203.7,\n",
       "  '00:05:00'],\n",
       " [100, 88201737, 147001, 0.5, 1.0, 1.3, 165.8, '00:10:00'],\n",
       " [200,\n",
       "  132617034,\n",
       "  221027,\n",
       "  0.69999999999999996,\n",
       "  1.4549999999999998,\n",
       "  2.819,\n",
       "  202.8,\n",
       "  '00:10:00'],\n",
       " [400,\n",
       "  172053376,\n",
       "  286750,\n",
       "  0.90000000000000002,\n",
       "  2.7999999999999998,\n",
       "  5.2809999999999997,\n",
       "  398.3,\n",
       "  '00:10:00'],\n",
       " [800,\n",
       "  192706739,\n",
       "  321178,\n",
       "  1.3,\n",
       "  5.3049999999999997,\n",
       "  9.9000000000000004,\n",
       "  10228.2,\n",
       "  '00:10:00'],\n",
       " [1600, 198542059, 330896, 2.0, 11.1, 23.204999999999998, 7952.4, '00:10:00'],\n",
       " [3200,\n",
       "  573617864,\n",
       "  318781,\n",
       "  3.5,\n",
       "  19.699999999999999,\n",
       "  45.004999999999995,\n",
       "  12904.2,\n",
       "  '00:29:59'],\n",
       " [5000,\n",
       "  580920345,\n",
       "  322734,\n",
       "  5.7999999999999998,\n",
       "  31.699999999999999,\n",
       "  64.302000000000007,\n",
       "  13338.4,\n",
       "  '00:30:00'],\n",
       " [6000,\n",
       "  1137540200,\n",
       "  316007,\n",
       "  6.7999999999999998,\n",
       "  33.200000000000003,\n",
       "  70.100999999999985,\n",
       "  15280.4,\n",
       "  '01:00:00'],\n",
       " [7000,\n",
       "  1146288352,\n",
       "  318415,\n",
       "  7.9000000000000004,\n",
       "  39.280000000000001,\n",
       "  75.156000000000006,\n",
       "  14498.7,\n",
       "  '01:00:00'],\n",
       " [8000,\n",
       "  1141405644,\n",
       "  317034,\n",
       "  9.1999999999999993,\n",
       "  45.600000000000001,\n",
       "  88.910000000000011,\n",
       "  26445.9,\n",
       "  '00:59:59'],\n",
       " [9000,\n",
       "  1492160316,\n",
       "  310850,\n",
       "  10.1,\n",
       "  51.799999999999997,\n",
       "  98.869,\n",
       "  28970.3,\n",
       "  '01:20:00'],\n",
       " [10000,\n",
       "  1518306852,\n",
       "  316316,\n",
       "  11.5,\n",
       "  55.150000000000006,\n",
       "  101.71499999999999,\n",
       "  29907.5,\n",
       "  '01:20:00']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_matrix_write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next table represents the results for the **READ** Operations:\n",
    "\n",
    "---\n",
    "\n",
    "*Table 2. \"Cassandra Performance over READ Operation.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_file = open(\"read_stats_\" + str(datetime.now().strftime(\"%m%d%Y_%H%M%S\")) + \".txt\", \"w\")\n",
    "text_file.write(\"%s\" % data_matrix_read)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td># Clients</td><td>total_ops</td><td>op/s</td><td>med</td><td>.95</td><td>.99</td><td>max</td><td>op_time</td></tr><tr><td>10</td><td>5602356</td><td>18674</td><td>0.4</td><td>0.8</td><td>1.5</td><td>70.2</td><td>5</td></tr><tr><td>100</td><td>83973752</td><td>139955</td><td>0.6</td><td>1.08</td><td>1.688</td><td>102.1</td><td>10</td></tr><tr><td>200</td><td>120327348</td><td>200544</td><td>0.8</td><td>1.755</td><td>2.782</td><td>50.1</td><td>10</td></tr><tr><td>400</td><td>146202779</td><td>243669</td><td>1.1</td><td>3.6</td><td>6.4</td><td>792.4</td><td>10</td></tr><tr><td>800</td><td>212690723</td><td>354484</td><td>1.3</td><td>6.3</td><td>12.0</td><td>210.2</td><td>10</td></tr><tr><td>1600</td><td>212281082</td><td>353797</td><td>2.3</td><td>12.6</td><td>27.205</td><td>139.6</td><td>10</td></tr><tr><td>3200</td><td>619437107</td><td>344125</td><td>4.0</td><td>27.505</td><td>46.7</td><td>659.6</td><td>30</td></tr><tr><td>5000</td><td>725438245</td><td>403026</td><td>5.1</td><td>39.6</td><td>65.351</td><td>2469.0</td><td>30</td></tr><tr><td>6000</td><td>1386394809</td><td>385114</td><td>7.9</td><td>43.5</td><td>73.2</td><td>3615.9</td><td>60</td></tr><tr><td>7000</td><td>1389277009</td><td>385907</td><td>3.7</td><td>61.9</td><td>94.4</td><td>4805.6</td><td>60</td></tr><tr><td>8000</td><td>1375211033</td><td>382008</td><td>10.3</td><td>58.15</td><td>89.2</td><td>4582.8</td><td>60</td></tr><tr><td>9000</td><td>1820464408</td><td>379262</td><td>8.2</td><td>66.9</td><td>98.838</td><td>3622.7</td><td>80</td></tr><tr><td>10000</td><td>2110372437</td><td>439654</td><td>11.6</td><td>58.93</td><td>90.526</td><td>26406.0</td><td>80</td></tr></table>"
      ],
      "text/plain": [
       "[['# Clients', 'total_ops', 'op/s', 'med', '.95', '.99', 'max', 'op_time'],\n",
       " [10, 5602356, 18674, 0.40000000000000002, 0.80000000000000004, 1.5, 70.2, 5],\n",
       " [100,\n",
       "  83973752,\n",
       "  139955,\n",
       "  0.59999999999999998,\n",
       "  1.0800000000000001,\n",
       "  1.6879999999999999,\n",
       "  102.1,\n",
       "  10],\n",
       " [200,\n",
       "  120327348,\n",
       "  200544,\n",
       "  0.80000000000000004,\n",
       "  1.7549999999999999,\n",
       "  2.7819999999999996,\n",
       "  50.1,\n",
       "  10],\n",
       " [400,\n",
       "  146202779,\n",
       "  243669,\n",
       "  1.1000000000000001,\n",
       "  3.6000000000000001,\n",
       "  6.4000000000000004,\n",
       "  792.4,\n",
       "  10],\n",
       " [800, 212690723, 354484, 1.3, 6.2999999999999998, 12.0, 210.2, 10],\n",
       " [1600,\n",
       "  212281082,\n",
       "  353797,\n",
       "  2.2999999999999998,\n",
       "  12.6,\n",
       "  27.204999999999998,\n",
       "  139.6,\n",
       "  10],\n",
       " [3200,\n",
       "  619437107,\n",
       "  344125,\n",
       "  4.0,\n",
       "  27.504999999999999,\n",
       "  46.700000000000003,\n",
       "  659.6,\n",
       "  30],\n",
       " [5000,\n",
       "  725438245,\n",
       "  403026,\n",
       "  5.0999999999999996,\n",
       "  39.600000000000001,\n",
       "  65.350999999999999,\n",
       "  2469.0,\n",
       "  30],\n",
       " [6000,\n",
       "  1386394809,\n",
       "  385114,\n",
       "  7.9000000000000004,\n",
       "  43.5,\n",
       "  73.200000000000003,\n",
       "  3615.9,\n",
       "  60],\n",
       " [7000,\n",
       "  1389277009,\n",
       "  385907,\n",
       "  3.7000000000000002,\n",
       "  61.899999999999991,\n",
       "  94.400000000000006,\n",
       "  4805.6,\n",
       "  60],\n",
       " [8000,\n",
       "  1375211033,\n",
       "  382008,\n",
       "  10.300000000000001,\n",
       "  58.150000000000006,\n",
       "  89.200000000000003,\n",
       "  4582.8,\n",
       "  60],\n",
       " [9000,\n",
       "  1820464408,\n",
       "  379262,\n",
       "  8.1999999999999993,\n",
       "  66.900000000000006,\n",
       "  98.837999999999994,\n",
       "  3622.7,\n",
       "  80],\n",
       " [10000,\n",
       "  2110372437,\n",
       "  439654,\n",
       "  11.6,\n",
       "  58.929999999999993,\n",
       "  90.525999999999996,\n",
       "  26406.0,\n",
       "  80]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_matrix_read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Generation: Graphs\n",
    "\n",
    "Next, results are displayed in Graphs. \n",
    "\n",
    "--- \n",
    "\n",
    "**IMPORTANT**\n",
    "\n",
    "Please, MODIFY the graphs name here if desired. Otherwise, graphs are indexed by datetime. \n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "ops_second_graph_filename = \"hCassandra_ops_\" + str(datetime.now().strftime(\"%m%d%Y_%H%M%S\"))\n",
    "median_latency_graph_filename = \"hCassandra_med_\" + str(datetime.now().strftime(\"%m%d%Y_%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def asint(s):\n",
    "    try: return int(s), ''\n",
    "    except ValueError: return sys.maxint, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "import operator\n",
    "import numpy\n",
    "import collections\n",
    "\n",
    "data_matrix = [['# ops', '# Clients', 'total_ops', 'op/s', 'pk/s', 'med', '.95', '.99', 'max', 'max_ms', 'sdv_ms', 'op_time']]\n",
    "\n",
    "traces_plot1 = []\n",
    "traces_plot2 = []\n",
    "bar_plot1 = []\n",
    "bar_plot2 = []\n",
    "\n",
    "# For each trace = client count\n",
    "for ops_count, tests_per_trace in results_per_ops.iteritems():\n",
    "    \n",
    "    total_ops = []\n",
    "    op_s = []\n",
    "    op_s_r = []\n",
    "    pk_s = []\n",
    "    med = []\n",
    "    med_r = []\n",
    "    p95 = []\n",
    "    p99 = []\n",
    "    max_lat = []\n",
    "    max_ms = []\n",
    "    sdv_ms = []\n",
    "    op_time = []\n",
    "    \n",
    "    clients = []\n",
    "    # Sort list by # Clients\n",
    "    sortedlist = [(k, tests_per_trace[k]) for k in sorted(tests_per_trace, key=asint)]\n",
    "    \n",
    "    for test in sortedlist:\n",
    "    #for k in sorted(tests_per_trace):\n",
    "        clients.append(test[0])\n",
    "        op_s.append(sum((ops for ops in test[1]['write']['op/s'])))\n",
    "        med.append(numpy.median(test[1]['write']['med']))\n",
    "        op_s_r.append(sum((ops for ops in test[1]['read']['op/s'])))\n",
    "        med_r.append(numpy.median(test[1]['read']['med']))\n",
    "        p99.append(numpy.percentile(test[1]['write']['.99'], 99))\n",
    "        max_lat.append(max(test[1]['write']['max']))\n",
    "\n",
    "        # Un-Comment for any other feature you want to depict...\n",
    "        #total_ops.append(sum((ops for ops in res_dict['write']['total ops'])))\n",
    "        #pk_s.append(res_dict['write']['pk/s'])\n",
    "        #p95.append(res_dict['write']['.95'])\n",
    "        #max_ms.append(res_dict['write']['max_ms'])\n",
    "        #sdv_ms.append(res_dict['write']['sdv_ms'])\n",
    "        #op_time.append(res_dict['write']['op_time'])\n",
    "        \n",
    "        \n",
    "    trace_plot1 = Scatter(\n",
    "          x=clients,\n",
    "          y=op_s, \n",
    "          mode = 'lines+markers',\n",
    "          name = 'WRITE',\n",
    "          marker = dict(\n",
    "            size = 10,\n",
    "            color = 'rgb(91,79,224)')\n",
    "        )\n",
    "    \n",
    "    trace_plot2 = Scatter(\n",
    "          x=clients,\n",
    "          y=op_s_r, \n",
    "          mode = 'lines+markers',\n",
    "          name = 'READ',\n",
    "          marker = dict(\n",
    "            size = 10,\n",
    "            color = 'rgb(212,224,79)')\n",
    "        )\n",
    "        \n",
    "    trace_plot3 = Scatter(\n",
    "          x=clients,\n",
    "          y=med, \n",
    "          mode = 'lines+markers',\n",
    "          name = 'WRITE-median', \n",
    "          marker = dict(\n",
    "            size = 10,\n",
    "            color = 'rgb(91,79,224)')\n",
    "        )\n",
    "\n",
    "    trace_plot4 = Scatter(\n",
    "          x=clients,\n",
    "          y=med_r, \n",
    "          mode = 'lines+markers',\n",
    "          name = 'READ-median', \n",
    "          marker = dict(\n",
    "            size = 10,\n",
    "            color = 'rgb(212,224,79)')\n",
    "        )\n",
    "    trace_plot5 = Scatter(\n",
    "          x=clients,\n",
    "          y=p99, \n",
    "          mode = 'lines+markers',\n",
    "          name = 'WRITE-percentile 99', \n",
    "          marker = dict(\n",
    "            size = 10,\n",
    "            color = 'rgb(222,44,118)')\n",
    "        )\n",
    "    trace_plot7 = Scatter(\n",
    "          x=clients,\n",
    "          y=max_lat, \n",
    "          mode = 'lines+markers',\n",
    "          name = 'WRITE-max', \n",
    "          marker = dict(\n",
    "            size = 10,\n",
    "            color = 'rgb(29,113,204)')\n",
    "        )\n",
    "    \n",
    "    traces_plot1.append(trace_plot1)\n",
    "    traces_plot1.append(trace_plot2)\n",
    "    traces_plot2.append(trace_plot3)\n",
    "    traces_plot2.append(trace_plot4)\n",
    "    traces_plot2.append(trace_plot5)\n",
    "    traces_plot2.append(trace_plot7)\n",
    "\n",
    "\n",
    "    trace1 = go.Bar(\n",
    "        x=clients,\n",
    "        y=op_s,\n",
    "        name='WRITE',\n",
    "        marker=dict(\n",
    "        color='rgb(91,79,224)'\n",
    "        )\n",
    "        )\n",
    "    trace2 = go.Bar(\n",
    "        x=clients,\n",
    "        y=op_s_r,\n",
    "        name='READ',\n",
    "        marker=dict(\n",
    "        color='rgb(212,224,79)')\n",
    "         )\n",
    "    trace3 = go.Bar(\n",
    "        x=clients,\n",
    "        y=med,\n",
    "        name='WRITE',\n",
    "        marker=dict(\n",
    "        color='rgb(91,79,224)'\n",
    "        )\n",
    "        )\n",
    "    trace4 = go.Bar(\n",
    "        x=clients,\n",
    "        y=med_r,\n",
    "        name='READ',\n",
    "        marker=dict(\n",
    "        color='rgb(212,224,79)')\n",
    "         )\n",
    "    trace5 = go.Bar(\n",
    "        x=clients,\n",
    "        y=p99,\n",
    "        name='WRITE-percentile 99',\n",
    "        marker=dict(\n",
    "        color='rgb(222,44,118)'\n",
    "        )\n",
    "        )\n",
    "    trace7 = go.Bar(\n",
    "        x=clients,\n",
    "        y=max_lat,\n",
    "        name='WRITE-max',\n",
    "        marker=dict(\n",
    "        color='rgb(29,113,204)')\n",
    "         )\n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Generation: operations per second vs. client count\n",
    "\n",
    "The following graph illustrates how, the number of operations per second changes while the number of clients increases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~anny.martinez/256.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture plot_operations --no-stdout\n",
    "\n",
    "data = Data(traces_plot1)\n",
    "# Edit the layout\n",
    "layout = dict(title = 'op/s vs. # Clients',\n",
    "              xaxis = dict(title = '# clients'),\n",
    "              yaxis = dict(title = 'op/s'),\n",
    "              )\n",
    "\n",
    "# Plot and embed in notebook\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename = ops_second_graph_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~anny.martinez/258.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture plot_operations --no-stdout\n",
    "\n",
    "data = [trace1, trace2]\n",
    "layout = go.Layout(\n",
    "    barmode='group'\n",
    ")\n",
    "\n",
    "layout = go.Layout(             # all \"layout\" attributes: /python/reference/#layout\n",
    "    title=\"Ops/sec\",     # more about \"layout's\" \"title\": /python/reference/#layout-title\n",
    "    xaxis=dict(                 # all \"layout's\" \"xaxis\" attributes: /python/reference/#layout-xaxis\n",
    "        type=\"category\",\n",
    "        title=\"Client #\"            # more about \"layout's\" \"xaxis's\" \"title\": /python/reference/#layout-xaxis-title\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "filename = \"bar\" + ops_second_graph_filename\n",
    "py.iplot(fig, filename=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Generation: median latency vs. client count\n",
    "\n",
    "The following graph illustrates median latency in miliseconds for each operation during that run as the number of clients increases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~anny.martinez/260.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture plot_med --no-stdout\n",
    "\n",
    "data = Data(traces_plot2)\n",
    "# Edit the layout\n",
    "layout = dict(title = 'Latency vs. Client Count',\n",
    "              xaxis = dict(title = '# Clients'),\n",
    "              yaxis = dict(title = 'Latency [ms]'),\n",
    "              )\n",
    "\n",
    "# Plot and embed in notebook\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename = median_latency_graph_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~anny.martinez/262.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture plot_operations --no-stdout\n",
    "\n",
    "data = [trace3, trace4, trace5]\n",
    "layout = go.Layout(\n",
    "    barmode='group'\n",
    ")\n",
    "\n",
    "layout = go.Layout(         \n",
    "    title=\"Latency\",    \n",
    "    xaxis=dict(                 \n",
    "        type=\"category\",\n",
    "        title=\"Client #\"   \n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "filename = \"bar\" + median_latency_graph_filename\n",
    "py.iplot(fig, filename=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, these benchmarks represent the **maximum throughput** of a 3 node cluster for the *default* model generated by the cassandra-stress tool. For accurate performance assessment of an application a range of parameters (including data model, queries, etc.) need to be adjusted. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
